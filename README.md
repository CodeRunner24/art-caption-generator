# üé® Art Caption Generator

A fine-tuned BLIP model for generating descriptive captions of artwork images, optimized for art-specific terminology and visual analysis.

## ‚ú® Features

- üé® **Fine-tuned BLIP Model**: Specialized for art image captioning
- üñºÔ∏è **Multiple Generation Modes**: Conservative, Balanced, and Creative
- üîç **Advanced Analysis**: Multi-perspective artwork analysis
- üìã **Clipboard Support**: Paste images directly (Ctrl+V / Cmd+V)
- üåê **Interactive Demo**: User-friendly Gradio interface
- ‚ö° **Metal GPU Support**: Optimized for Apple Silicon (M1/M2/M3)

## üöÄ Quick Start

### 1. Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Dataset

Create the following structure:
```
art_captioning/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ ArtCap.json                 # Captions in JSON format
‚îÇ   ‚îî‚îÄ‚îÄ ArtCap_Images_Dataset/      # Image files
‚îî‚îÄ‚îÄ models/
    ‚îî‚îÄ‚îÄ model_base_capfilt_large.pth  # Pre-trained BLIP model
```

**Dataset Format (ArtCap.json):**
```json
{
  "image1.jpg": [
    "caption 1 for image1",
    "caption 2 for image1",
    "caption 3 for image1"
  ],
  "image2.jpg": [
    "caption 1 for image2",
    "caption 2 for image2"
  ]
}
```

### 3. Training

```bash
cd art_captioning
python src/train.py
```

### 4. Testing

```bash
python src/test.py
```

### 5. Demo

```bash
python src/demo.py
```

## üìä Model Performance

Our fine-tuned model achieves:
- **Training Loss**: 0.45 (final epoch)
- **Validation Loss**: 1.98 (best model at epoch 2)
- **Generation Speed**: ~2.3 it/s on Apple M3

### Training Progress
- **Epoch 1**: Train: 2.31 ‚Üí Val: 2.06
- **Epoch 2**: Train: 1.75 ‚Üí Val: 1.98 ‚úÖ (Best Model)
- **Epoch 3**: Train: 1.26 ‚Üí Val: 2.02
- **Epoch 4**: Train: 0.76 ‚Üí Val: 2.16
- **Epoch 5**: Train: 0.45 ‚Üí Val: 2.30

## üéØ Generation Modes

### Conservative Mode
- Uses beam search for reliable results
- More factual and straightforward descriptions
- Best for accuracy-focused applications

### Balanced Mode  
- Hybrid approach (beam + sampling)
- Good balance between creativity and accuracy
- Recommended for most use cases

### Creative Mode
- High temperature sampling
- More unique and artistic descriptions
- Best for creative and experimental captions

## üìÅ Project Structure

```
art_captioning/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ train.py          # Training script
‚îÇ   ‚îú‚îÄ‚îÄ test.py           # Model evaluation
‚îÇ   ‚îú‚îÄ‚îÄ demo.py           # Gradio interface
‚îÇ   ‚îî‚îÄ‚îÄ utils.py          # Helper functions
‚îú‚îÄ‚îÄ data/                 # Dataset (not included)
‚îú‚îÄ‚îÄ models/               # Model files (not included)
‚îú‚îÄ‚îÄ outputs/              # Training outputs
‚îú‚îÄ‚îÄ requirements.txt      # Dependencies
‚îî‚îÄ‚îÄ README.md
```

## üõ†Ô∏è Technical Details

### Model Architecture
- **Base Model**: Salesforce/blip-image-captioning-base
- **Parameters**: 247M total (161M trainable)
- **Fine-tuning**: Text decoder only (vision encoder frozen)
- **Optimization**: AdamW with cosine scheduler

### Training Configuration
- **Dataset**: 18,030 image-caption pairs
- **Split**: 80% train, 10% validation, 10% test  
- **Batch Size**: 4
- **Learning Rate**: 1e-4
- **Epochs**: 5
- **Hardware**: Apple M3 with Metal Performance Shaders

### Supported Features
- Art terminology recognition
- Style identification (abstract, realistic, impressionist)
- Technique description (oil painting, watercolor, brushstroke)
- Composition analysis (foreground, background, perspective)

## üîß Requirements

```txt
torch>=2.0.0
transformers>=4.30.0
gradio>=3.35.0
Pillow>=9.5.0
tqdm>=4.65.0
matplotlib>=3.7.0
numpy>=1.24.0
```

## üíª Hardware Requirements

### Minimum
- RAM: 8GB
- Storage: 5GB free space
- GPU: Optional (CPU supported)

### Recommended  
- RAM: 16GB+
- GPU: Apple Silicon (M1/M2/M3) or NVIDIA GPU
- Storage: 10GB free space

## üöÄ Usage Examples

### Basic Caption Generation
```python
from src.demo import ArtCaptionDemo
from PIL import Image

# Load model
demo = ArtCaptionDemo("outputs/best_model.pth")

# Generate caption
image = Image.open("artwork.jpg")
caption = demo.generate_caption(image, generation_mode="Balanced")
print(caption)
```

### Advanced Analysis
```python
# Multi-perspective analysis
analysis = demo.analyze_art_features(image)
print(analysis)
```

## üìà Results Examples

**Input**: Van Gogh's Starry Night  
**Output**: "a painting of a swirling night sky with bright stars over a village with a prominent church spire"

**Input**: Picasso's Les Demoiselles d'Avignon  
**Output**: "an abstract painting featuring geometric faces and fragmented forms in earth tones"


---

‚≠ê If you find this project helpful, please give it a star on GitHub! 
